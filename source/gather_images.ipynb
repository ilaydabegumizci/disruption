{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os.path\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_list=[\"baroque\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/iizci/Desktop/kozmik_sefer/data_set/baroque\n"
     ]
    }
   ],
   "source": [
    "for movement in movement_list:\n",
    "    file_path = \"/Users/iizci/Desktop/kozmik_sefer/data_set\"+\"/\"+str(movement)\n",
    "    print(file_path)\n",
    "    if path.exists(file_path) == False:\n",
    "      os.mkdir(file_path)\n",
    "      os.chdir(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.wikiart.org/en/Alphabet/a/text-list\n"
     ]
    },
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/iizci/Desktop/Documents/Projeler/Python Notebooks/HH_Notebooks/gather_images.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/iizci/Desktop/Documents/Projeler/Python%20Notebooks/HH_Notebooks/gather_images.ipynb#ch0000005?line=5'>6</a>\u001b[0m artist_list_url \u001b[39m=\u001b[39m base_url \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/en/Alphabet/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m char \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/text-list\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/iizci/Desktop/Documents/Projeler/Python%20Notebooks/HH_Notebooks/gather_images.ipynb#ch0000005?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(artist_list_url)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/iizci/Desktop/Documents/Projeler/Python%20Notebooks/HH_Notebooks/gather_images.ipynb#ch0000005?line=8'>9</a>\u001b[0m genre_soup \u001b[39m=\u001b[39m BeautifulSoup(urllib\u001b[39m.\u001b[39;49mrequest\u001b[39m.\u001b[39;49murlopen(artist_list_url), \u001b[39m\"\u001b[39;49m\u001b[39mlxml\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/iizci/Desktop/Documents/Projeler/Python%20Notebooks/HH_Notebooks/gather_images.ipynb#ch0000005?line=9'>10</a>\u001b[0m artist_list_main \u001b[39m=\u001b[39m genre_soup\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/iizci/Desktop/Documents/Projeler/Python%20Notebooks/HH_Notebooks/gather_images.ipynb#ch0000005?line=10'>11</a>\u001b[0m lis \u001b[39m=\u001b[39m artist_list_main\u001b[39m.\u001b[39mfind_all(\u001b[39m\"\u001b[39m\u001b[39mli\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/bs4/__init__.py:248\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     builder_class \u001b[39m=\u001b[39m builder_registry\u001b[39m.\u001b[39mlookup(\u001b[39m*\u001b[39mfeatures)\n\u001b[1;32m    247\u001b[0m     \u001b[39mif\u001b[39;00m builder_class \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 248\u001b[0m         \u001b[39mraise\u001b[39;00m FeatureNotFound(\n\u001b[1;32m    249\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find a tree builder with the features you \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequested: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m. Do you need to install a parser library?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m             \u001b[39m%\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(features))\n\u001b[1;32m    253\u001b[0m \u001b[39m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[39m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[39m# with the remaining **kwargs.\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[39mif\u001b[39;00m builder \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.wikiart.org\"\n",
    "# iterate through all artists by last name alphabetically\n",
    "# like this https://www.wikiart.org/en/Alphabet/m/text-list\n",
    "for c in range(ord('a'), ord('z') + 1):\n",
    "  char = chr(c)\n",
    "  artist_list_url = base_url + \"/en/Alphabet/\" + char + \"/text-list\"\n",
    "  print(artist_list_url)\n",
    "\n",
    "  genre_soup = BeautifulSoup(urllib.request.urlopen(artist_list_url), \"lxml\")\n",
    "  artist_list_main = genre_soup.find(\"main\")\n",
    "  lis = artist_list_main.find_all(\"li\")\n",
    "\n",
    "  # for each list element\n",
    "  for li in lis: \n",
    "    born = 0\n",
    "    died = 0\n",
    "\n",
    "    # get the date range\n",
    "    for line in li.text.splitlines():\n",
    "      if line.startswith(\",\") and \"-\" in line:\n",
    "        parts = line.split('-')\n",
    "        if len(parts) == 2:\n",
    "          born = int(re.sub(\"[^0-9]\", \"\",parts[0]))\n",
    "          died = int(re.sub(\"[^0-9]\", \"\",parts[1]))\n",
    "\n",
    "    link = li.find(\"a\")\n",
    "    artist = link.attrs[\"href\"]\n",
    "\n",
    "    # get the artist's main page\n",
    "    artist_url = base_url + artist\n",
    "    artist_soup = BeautifulSoup(urllib.request.urlopen(artist_url), \"lxml\")\n",
    "\n",
    "    # only look for artists with the word abstract on their main page\n",
    "    for movement in movement_list:\n",
    "      if movement in artist_soup.text: \n",
    "        print(artist + \" \" + str(born) + \" - \" + str(died))\n",
    "        #artist_soup.text\n",
    "\n",
    "        # get the artist's web page for the artwork\n",
    "        url = base_url + artist + '/all-works/text-list'\n",
    "        artist_work_soup = BeautifulSoup(urllib.request.urlopen(url), \"lxml\")\n",
    "\n",
    "        # get the main section\n",
    "        artist_main = artist_work_soup.find(\"main\")\n",
    "        image_count = 0\n",
    "        artist_name = artist.split(\"/\")[2]\n",
    "        # get the list of artwork\n",
    "        lis = artist_main.find_all(\"li\")\n",
    "\n",
    "        # for each list element\n",
    "        for li in lis:\n",
    "          link = li.find(\"a\")\n",
    "\n",
    "          if link != None:\n",
    "            painting = link.attrs[\"href\"]\n",
    "\n",
    "            # get the painting\n",
    "            url = base_url + painting\n",
    "            print(url)\n",
    "\n",
    "            try:\n",
    "              painting_soup = BeautifulSoup(urllib.request.urlopen(url), \"lxml\")\n",
    "\n",
    "            except:\n",
    "              print(\"error retreiving page\")\n",
    "              continue\n",
    "\n",
    "            #check the genre\n",
    "            field = painting_soup.find(\"span\", {\"itemprop\":\"field\"})\n",
    "            if field == None or field.text in field_list:\n",
    "              print(\"field :\",field)\n",
    "\n",
    "              # get the url\n",
    "              og_image = painting_soup.find(\"meta\", {\"property\":\"og:image\"})\n",
    "              image_url = og_image[\"content\"].split(\"!\")[0] # ignore the !Large.jpg at the end\n",
    "              print(image_url)\n",
    "\n",
    "              parts = url.split(\"/\")\n",
    "              painting_name = parts[-1]\n",
    "              file_path=\"/Users/iizci/Desktop/kozmik_sefer/data_set\"+\"/\"+str(movement)\n",
    "              save_path = file_path + \"/\" + artist_name + \"_\" + painting_name + \".jpg\"\n",
    "\n",
    "              #download the file\n",
    "              try:\n",
    "                print(\"downloading to \" + save_path)\n",
    "                time.sleep(0.2)  # try not to get a 403                    \n",
    "                urllib.request.urlretrieve(image_url, save_path)\n",
    "                image_count = image_count + 1\n",
    "              except Exception as e:\n",
    "                print(\"failed downloading \" + image_url, e) \n",
    "        break              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chosen_artist in artist_list:\n",
    "  file_path = \"/Users/iizci/Desktop/kozmik_sefer/data_set\"+\"/\"+str(chosen_artist)\n",
    "  print(file_path)\n",
    "  if path.exists(file_path) == False:\n",
    "    os.mkdir(file_path)\n",
    "    os.chdir(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_list=[\"rembrandt\",\"caravaggio\"]\n",
    "artist_list.sort()\n",
    "char_list=[]\n",
    "for  artist_index in range(len(artist_list)):\n",
    "   char_list.append(ord(artist_list[artist_index][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.wikiart.org/en/Alphabet/c/text-list\n"
     ]
    },
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/iizci/Desktop/Documents/Projeler/Python Notebooks/HH_Notebooks/gather_images.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/iizci/Desktop/Documents/Projeler/Python%20Notebooks/HH_Notebooks/gather_images.ipynb#ch0000007?line=6'>7</a>\u001b[0m artist_list_url \u001b[39m=\u001b[39m base_url \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/en/Alphabet/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m char \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/text-list\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/iizci/Desktop/Documents/Projeler/Python%20Notebooks/HH_Notebooks/gather_images.ipynb#ch0000007?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(artist_list_url)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/iizci/Desktop/Documents/Projeler/Python%20Notebooks/HH_Notebooks/gather_images.ipynb#ch0000007?line=9'>10</a>\u001b[0m genre_soup \u001b[39m=\u001b[39m BeautifulSoup(urllib\u001b[39m.\u001b[39;49mrequest\u001b[39m.\u001b[39;49murlopen(artist_list_url), \u001b[39m\"\u001b[39;49m\u001b[39mlxml\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/iizci/Desktop/Documents/Projeler/Python%20Notebooks/HH_Notebooks/gather_images.ipynb#ch0000007?line=10'>11</a>\u001b[0m artist_list_main \u001b[39m=\u001b[39m genre_soup\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/iizci/Desktop/Documents/Projeler/Python%20Notebooks/HH_Notebooks/gather_images.ipynb#ch0000007?line=11'>12</a>\u001b[0m lis \u001b[39m=\u001b[39m artist_list_main\u001b[39m.\u001b[39mfind_all(\u001b[39m\"\u001b[39m\u001b[39mli\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/bs4/__init__.py:248\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     builder_class \u001b[39m=\u001b[39m builder_registry\u001b[39m.\u001b[39mlookup(\u001b[39m*\u001b[39mfeatures)\n\u001b[1;32m    247\u001b[0m     \u001b[39mif\u001b[39;00m builder_class \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 248\u001b[0m         \u001b[39mraise\u001b[39;00m FeatureNotFound(\n\u001b[1;32m    249\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find a tree builder with the features you \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequested: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m. Do you need to install a parser library?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m             \u001b[39m%\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(features))\n\u001b[1;32m    253\u001b[0m \u001b[39m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[39m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[39m# with the remaining **kwargs.\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[39mif\u001b[39;00m builder \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.wikiart.org\"\n",
    "\n",
    "# iterate through all artists by last name alphabetically\n",
    "# like this https://www.wikiart.org/en/Alphabet/m/text-list\n",
    "for c in char_list:\n",
    "  char = chr(c)\n",
    "  artist_list_url = base_url + \"/en/Alphabet/\" + char + \"/text-list\"\n",
    "  print(artist_list_url)\n",
    "\n",
    "  genre_soup = BeautifulSoup(urllib.request.urlopen(artist_list_url), \"lxml\")\n",
    "  artist_list_main = genre_soup.find(\"main\")\n",
    "  lis = artist_list_main.find_all(\"li\")\n",
    "\n",
    "  # for each list element\n",
    "  for li in lis: \n",
    "    born = 0\n",
    "    died = 0\n",
    "\n",
    "    # get the date range\n",
    "    for line in li.text.splitlines():\n",
    "      if line.startswith(\",\") and \"-\" in line:\n",
    "        parts = line.split('-')\n",
    "        if len(parts) == 2:\n",
    "          born = int(re.sub(\"[^0-9]\", \"\",parts[0]))\n",
    "          died = int(re.sub(\"[^0-9]\", \"\",parts[1]))\n",
    "\n",
    "    link = li.find(\"a\")\n",
    "    artist = link.attrs[\"href\"]\n",
    "\n",
    "    # get the artist's main page\n",
    "    artist_url = base_url + artist\n",
    "    artist_soup = BeautifulSoup(urllib.request.urlopen(artist_url), \"lxml\")\n",
    "\n",
    "    # only look for artists with the word abstract on their main page\n",
    "    print(artist + \" \" + str(born) + \" - \" + str(died))\n",
    "    #artist_soup.text\n",
    "\n",
    "    # get the artist's web page for the artwork\n",
    "    url = base_url + artist + '/all-works/text-list'\n",
    "    artist_work_soup = BeautifulSoup(urllib.request.urlopen(url), \"lxml\")\n",
    "\n",
    "    # get the main section\n",
    "    artist_main = artist_work_soup.find(\"main\")\n",
    "    image_count = 0\n",
    "    artist_name = artist.split(\"/\")[2]\n",
    "    if chosen_artist in artist_name:\n",
    "      # get the list of artwork\n",
    "      lis = artist_main.find_all(\"li\")\n",
    "\n",
    "      # for each list element\n",
    "      for li in lis:\n",
    "        link = li.find(\"a\")\n",
    "\n",
    "        if link != None:\n",
    "          painting = link.attrs[\"href\"]\n",
    "\n",
    "          # get the painting\n",
    "          url = base_url + painting\n",
    "          print(url)\n",
    "\n",
    "          try:\n",
    "            painting_soup = BeautifulSoup(urllib.request.urlopen(url), \"lxml\")\n",
    "\n",
    "          except:\n",
    "            print(\"error retreiving page\")\n",
    "            continue\n",
    "\n",
    "          #check the genre\n",
    "          field = painting_soup.find(\"span\", {\"itemprop\":\"field\"})\n",
    "          if field == None or field.text in field_list:\n",
    "            print(\"field :\",field)\n",
    "\n",
    "            # get the url\n",
    "            og_image = painting_soup.find(\"meta\", {\"property\":\"og:image\"})\n",
    "            image_url = og_image[\"content\"].split(\"!\")[0] # ignore the !Large.jpg at the end\n",
    "            print(image_url)\n",
    "\n",
    "            parts = url.split(\"/\")\n",
    "            painting_name = parts[-1]\n",
    "            file_path=\"/Users/iizci/Desktop/kozmik_sefer/data_set\"+\"/\"+str(chosen_artist)\n",
    "            save_path = file_path + \"/\" + artist_name + \"_\" + painting_name + \".jpg\"\n",
    "\n",
    "            #download the file\n",
    "            try:\n",
    "              print(\"downloading to \" + save_path)\n",
    "              time.sleep(0.2)  # try not to get a 403                    \n",
    "              urllib.request.urlretrieve(image_url, save_path)\n",
    "              image_count = image_count + 1\n",
    "            except Exception as e:\n",
    "              print(\"failed downloading \" + image_url, e) \n",
    "      break              "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
